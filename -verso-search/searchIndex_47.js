window.docContents[47].resolve({"/Induction-and-Recursion/#structural-recursion-and-induction":{"contents":"What makes the equation compiler powerful is that it also supports\nrecursive definitions. In the next three sections, we will describe,\nrespectively:\n\n* structurally recursive definitions* well-founded recursive definitions* mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following form:\n\ndef foo (a : α) : (b : β) → γ\n  | [patterns₁] => t₁\n  ...\n  | [patternsₙ] => tₙ\n\n\nHere (a : α) is a sequence of parameters, (b : β) is the\nsequence of arguments on which pattern matching takes place, and γ\nis any type, which can depend on a and b. Each line should\ncontain the same number of patterns, one for each element of β. As we\nhave seen, a pattern is either a variable, a constructor applied to\nother patterns, or an expression that normalizes to something of that\nform (where the non-constructors are marked with the [match_pattern]\nattribute). The appearances of constructors prompt case splits, with\nthe arguments to the constructors represented by the given\nvariables. In the section on dependent pattern matching,\nwe will see that some explicit terms in patterns are forced into a particular form\nin order to make an expression type check, though they do not play a\nrole in pattern matching. These are called “inaccessible patterns” for\nthat reason. But we will not need to use such inaccessible patterns\nbefore covering dependent pattern matching.\n\nAs we saw in the last section, the terms t₁, ..., tₙ can make use\nof any of the parameters a, as well as any of the variables that\nare introduced in the corresponding patterns. What makes recursion and\ninduction possible is that they can also involve recursive calls to\nfoo. In this section, we will deal with structural recursion, in\nwhich the arguments to foo occurring on the right-hand side of the\n=> are subterms of the patterns on the left-hand side. The idea is\nthat they are structurally smaller, and hence appear in the inductive\ntype at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation\ncompiler:\n\n\n\nThe proof of zero_add makes it clear that proof by induction is\nreally a form of recursion in Lean.\n\nThe example above shows that the defining equations for add hold\ndefinitionally, and the same is true of mul. The equation compiler\ntries to ensure that this holds whenever possible, as is the case with\nstraightforward structural induction. In other situations, however,\nreductions hold only propositionally, which is to say, they are\nequational theorems that must be applied explicitly. The equation\ncompiler generates such theorems internally. They are not meant to be\nused directly by the user; rather, the simp tactic\nis configured to use them when necessary. The following\nproof of zero_add works this way:\n\n\n\nAs with definition by pattern matching, parameters to a structural\nrecursion or induction may appear before the colon. Such parameters\nare simply added to the local context before the definition is\nprocessed. For example, the definition of addition may also be written\nas follows:\n\n\n\nYou can also write the example above using match.\n\n\n\nA more interesting example of structural recursion is given by the Fibonacci function fib.\n\nHere, the value of the fib function at n + 2 (which is\ndefinitionally equal to succ (succ n)\n) is defined in terms of the\nvalues at n + 1 (which is definitionally equivalent to succ n\n)\nand the value at n. This is a notoriously inefficient way of\ncomputing the Fibonacci function, however, with an execution time that\nis exponential in n\n. Here is a better way:\n\n\n\nHere is the same definition using a let rec instead of a where.\n\n\n\nIn both cases, Lean generates the auxiliary function fibFast.loop.\n\nTo handle structural recursion, the equation compiler uses\ncourse-of-values recursion, using constants below and brecOn\nthat are automatically generated with each inductively defined\ntype. You can get a sense of how it works by looking at the types of\nNat.below and Nat.brecOn:\n\nThe type @Nat.below C (3 : Nat)\n is a data structure that stores elements of C 0\n, C 1\n, and C 2\n.\nThe course-of-values recursion is implemented by Nat.brecOn. It enables us to define the value of a dependent\nfunction of type (n : Nat) → C n\n at a particular input n\n in terms of all the previous values of the function,\npresented as an element of @Nat.below C n\n.\n\nThe use of course-of-values recursion is one of the techniques the equation compiler uses to justify to\nthe Lean kernel that a function terminates. It does not affect the code generator which compiles recursive\nfunctions as other functional programming language compilers. Recall that #eval  fib <n> is exponential in <n>.\nOn the other hand, #reduce fib <n> is efficient because it uses the definition sent to the kernel that\nis based on the brecOn construction.\n\nAnother good example of a recursive definition is the list append function.\n\nHere is another: it adds elements of the first list to elements of the second list, until one of the two lists runs out.\n\n\n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n","context":"Theorem Proving in Lean 4\u0009Induction and Recursion","header":"8.3. Structural Recursion and Induction","id":"/Induction-and-Recursion/#structural-recursion-and-induction"}});