window.docContents[227].resolve({"/Axioms-and-Computation/#axioms-and-computation":{"id":"/Axioms-and-Computation/#axioms-and-computation","header":"12. Axioms and Computation","context":"Theorem Proving in Lean 4","contents":"We have seen that the version of the Calculus of Constructions that\nhas been implemented in Lean includes dependent function types,\ninductive types, and a hierarchy of universes that starts with an\nimpredicative, proof-irrelevant Prop\n at the bottom. In this\nchapter, we consider ways of extending the CIC with additional axioms\nand rules. Extending a foundational system in such a way is often\nconvenient; it can make it possible to prove more theorems, as well as\nmake it easier to prove theorems that could have been proved\notherwise. But there can be negative consequences of adding additional\naxioms, consequences which may go beyond concerns about their\ncorrectness. In particular, the use of axioms bears on the\ncomputational content of definitions and theorems, in ways we will\nexplore here.\n\nLean is designed to support both computational and classical\nreasoning. Users that are so inclined can stick to a “computationally\npure” fragment, which guarantees that closed expressions in the system\nevaluate to canonical normal forms. In particular, any closed\ncomputationally pure expression of type Nat\n, for example, will\nreduce to a numeral.\n\nLean's standard library defines an additional axiom, propositional\nextensionality, and a quotient construction which in turn implies the\nprinciple of function extensionality. These extensions are used, for\nexample, to develop theories of sets and finite sets. We will see\nbelow that using these theorems can block evaluation in Lean's kernel,\nso that closed terms of type Nat\n no longer evaluate to numerals. But\nLean erases types and propositional information when compiling\ndefinitions to executable code, and since\nthese axioms only add new propositions, they are compatible with that\ncomputational interpretation. Even computationally inclined users may\nwish to use the classical law of the excluded middle to reason about\ncomputation. This also blocks evaluation in the kernel, but it is\ncompatible with compiled code.\n\nThe standard library also defines a choice principle that is entirely\nantithetical to a computational interpretation, since it magically\nproduces “data” from a proposition asserting its existence. Its use is\nessential to some classical constructions, and users can import it\nwhen needed. But expressions that use this construction to produce\ndata do not have computational content, and in Lean we are required to\nmark such definitions as noncomputable to flag that fact.\n\nUsing a clever trick (known as Diaconescu's theorem), one can use\npropositional extensionality, function extensionality, and choice to\nderive the law of the excluded middle. As noted above, however, use of\nthe law of the excluded middle is still compatible with\ncompilation, as are other classical principles, as\nlong as they are not used to manufacture data.\n\nTo summarize, then, on top of the underlying framework of universes,\ndependent function types, and inductive types, the standard library\nadds three additional components:\n\n* the axiom of propositional extensionality* a quotient construction, which implies function extensionality* a choice principle, which produces data from an existential proposition.\n\nThe first two of these block normalization within Lean, but are\ncompatible with code generation, whereas the third is not amenable\nto computational interpretation. We will spell out the details more\nprecisely below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}});